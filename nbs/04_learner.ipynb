{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbaddb55-45b7-4308-88fc-708ce589208f",
   "metadata": {},
   "source": [
    "# Learner\n",
    "\n",
    "> Creating a *Learner* class. This is copied from the `miniai` library, created during the [Part 2](https://github.com/fastai/course22p2.git) of fast.ai courses. For more information on the *Learner* check [this](https://course.fast.ai/Lessons/lesson16.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39dd0f-777c-4b67-81af-ebe02d133cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b4e9d-26a1-4ee3-8e97-efd7187c6db4",
   "metadata": {},
   "source": [
    "### NOTE: THIS PAGE NEEDS FORMATING AND ADDING GENERAL FUNCTIONALITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7326d1f-cdf2-4849-afdb-83ac83f5e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from torcheval.metrics import Mean\n",
    "\n",
    "import fastcore.all as fc\n",
    "from fastprogress import progress_bar,master_bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from copy import copy\n",
    "from functools import partial\n",
    "from operator import attrgetter\n",
    "from collections.abc import Mapping\n",
    "\n",
    "from pclab.utils import def_device, to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9942a-1dd3-4cba-ba8d-dcd998a3230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping): return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list): return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): return tuple(to_cpu(list(x)))\n",
    "    res = x.detach().cpu()\n",
    "    return res.float() if res.dtype==torch.float16 else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583aad91-d725-4260-a8fb-9751fe53d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31ceeb-6519-4da7-88d0-ff5373531669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Callback(): order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9bbd6-ff2f-4065-bee3-3af2370b3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None: method(learn)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093aae5-7b13-4d1b-a1b9-f1fc44394884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6ff59-c243-4360-ac67-05d99c7615bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "\n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "\n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter,self.batch in enumerate(self.dl): self._one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, train, valid):\n",
    "        for self.epoch in self.epochs:\n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "\n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        # `add_cb` and `rm_cb` were added in lesson 18\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            if lr is None: lr = self.lr\n",
    "            if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(train, valid)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8d719-b19d-455b-bd19-04a9cf97191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainLearner(Learner):\n",
    "    def predict(self): self.preds = self.model(self.batch[0])\n",
    "    def get_loss(self): self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "    def backward(self): self.loss.backward()\n",
    "    def step(self): self.opt.step()\n",
    "    def zero_grad(self): self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c3f21-b830-45f0-bb95-0e75d8a7080d",
   "metadata": {},
   "source": [
    "# Basic Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bccb52a-de21-42cf-8560-106c50003725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1): self.n_inp = n_inp\n",
    "    def predict(self, learn): learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "    def get_loss(self, learn): learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f73cd-400c-4b2c-a190-d1ea66e93192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LRFinderCB(Callback):\n",
    "    def __init__(self, gamma=1.3, max_mult=3): fc.store_attr()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        self.sched = ExponentialLR(learn.opt, self.gamma)\n",
    "        self.lrs,self.losses = [],[]\n",
    "        self.min = math.inf\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        if not learn.training: raise CancelEpochException()\n",
    "        self.lrs.append(learn.opt.param_groups[0]['lr'])\n",
    "        loss = to_cpu(learn.loss)\n",
    "        self.losses.append(loss)\n",
    "        if loss < self.min: self.min = loss\n",
    "        if math.isnan(loss) or (loss > self.min*self.max_mult):\n",
    "            raise CancelFitException()\n",
    "        self.sched.step()\n",
    "\n",
    "    def cleanup_fit(self, learn):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee626c-6772-4f97-8cb3-56e9e1de210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35edad-e900-4576-b2a2-c01202589ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af059d20-710c-4eb6-bc52-b4140cc2673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order + 1\n",
    "    def __init__(self, plot=False): self.plot = plot\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d.values()), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "    \n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses: self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "            \n",
    "    def after_epoch(self, learn):\n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'): \n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618aa815-f664-4c70-a65b-dd14f9d6591a",
   "metadata": {},
   "source": [
    "### Scheduler Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba733fdb-166d-45d8-ae54-c37a71699eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class BaseSchedCB(Callback):\n",
    "    def __init__(self, sched): self.sched = sched\n",
    "    def before_fit(self, learn): self.schedo = self.sched(learn.opt)\n",
    "    def _step(self, learn):\n",
    "        if learn.training: self.schedo.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed61f3-d984-42c9-a142-fd24b2e311c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class BatchSchedCB(BaseSchedCB):\n",
    "    def after_batch(self, learn): self._step(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a2d12-ded0-435c-827d-dc88421bdf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpochSchedCB(BaseSchedCB):\n",
    "    def after_epoch(self, learn): self._step(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c992c87-1f0b-4e12-b92b-9c3ddc036322",
   "metadata": {},
   "source": [
    "### Adding LRFind to the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dc919-36c9-4cc2-a2bc-9147e5a1dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@fc.patch\n",
    "def lr_find(self:Learner, gamma=1.3, max_mult=3, start_lr=1e-5, max_epochs=10):\n",
    "    self.fit(max_epochs, lr=start_lr, cbs=LRFinderCB(gamma=gamma, max_mult=max_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54521c3a-6dba-4b83-9d2b-2c69f4772ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
