{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelNet40\n",
    "\n",
    "> A Dataset structure for ModelNet40 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets/modelnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to load the ModelNet40 dataset comes from the DGCNN repo. \n",
    "There are some alternations, so that it can store and load the data from a custom path. \n",
    "Also there is an option to load only a specific class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pclab.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def download(path:str = None): # if path is None, it will download the data on the current dir, under the `data` subfolder.\n",
    "    \"A functions that downloads the ModelNet40 data, if not already downloaded, in the specified path\"\n",
    "    # adding the ability to use custom path\n",
    "    if path == None:\n",
    "        BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "        DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "        # Creating the path is it doesn't exist\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.mkdir(DATA_DIR)\n",
    "    else:\n",
    "        DATA_DIR = path\n",
    "        \n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n",
    "        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n",
    "        zipfile = os.path.basename(www)\n",
    "        os.system('wget %s; unzip %s' % (www, zipfile))\n",
    "        os.system('mv %s %s' % (zipfile[:-4], DATA_DIR))\n",
    "        os.system('rm %s' % (zipfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### download\n",
       "\n",
       ">      download (path:str=None)\n",
       "\n",
       "A functions that downloads the ModelNet40 data, if not already downloaded, in the specified path\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str | None | if path is None, it will download the data on the current dir, under the `data` subfolder. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### download\n",
       "\n",
       ">      download (path:str=None)\n",
       "\n",
       "A functions that downloads the ModelNet40 data, if not already downloaded, in the specified path\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str | None | if path is None, it will download the data on the current dir, under the `data` subfolder. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_data(partition:str, # `train` or `test` partition\n",
    "              path:str=None):\n",
    "    download(path)\n",
    "    \n",
    "    if path is None:\n",
    "        BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "        DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    else:\n",
    "        DATA_DIR = path\n",
    "        \n",
    "    all_data = []\n",
    "    all_label = []\n",
    "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', 'ply_data_%s*.h5'%partition)):\n",
    "        f = h5py.File(h5_name)\n",
    "        data = f['data'][:].astype('float32')\n",
    "        label = f['label'][:].astype('int64')\n",
    "        f.close()\n",
    "        all_data.append(data)\n",
    "        all_label.append(label)\n",
    "        \n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    all_label = np.concatenate(all_label, axis=0)\n",
    "    \n",
    "    return all_data, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L36){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### load_data\n",
       "\n",
       ">      load_data (partition:str, path:str=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| partition | str |  | `train` or `test` partition |\n",
       "| path | str | None |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L36){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### load_data\n",
       "\n",
       ">      load_data (partition:str, path:str=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| partition | str |  | `train` or `test` partition |\n",
       "| path | str | None |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "m40_odered_labels = 'airplane bathtub bed bench bookshelf bottle bowl car chair cone \\\n",
    "cup curtain desk door dresser plower_pot glass_box guitar keyboard lamp \\\n",
    "laptop mantel monitor night_stand person piano plant radio range_hood sink \\\n",
    "sofa stairs stool table tent toilet tv_stand vase wardrobe xbox'.split(' ')\n",
    "\n",
    "m40_cat2int = {m40_odered_labels[i] : i for i in range(40)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The labels in the downloaded file are represented as integers. Therefore, it is necessary to establish a mapping that associates these integers with the actual labels of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('airplane', 'chair', 'person')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m40_odered_labels[0], m40_odered_labels[8], m40_odered_labels[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8, 24)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m40_cat2int['airplane'], m40_cat2int['chair'], m40_cat2int['person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class ModelNet40(Dataset):\n",
    "    \"A ModelNet40 class is necessary for loading and accessing the data, and it inherits from the torch.utils.Dataset class.\"\n",
    "    def __init__(self, \n",
    "                 path:str,               # path of the dataset\n",
    "                 num_points:int,         # number of points \n",
    "                 partition:str='train',  # which partition to use (`train` or `test`)\n",
    "                 transforms=[],          # the transforms to apply on each sample\n",
    "                 category=-1):           # select a specific category of the dataset either by index or by name. By default returns samples from all 40 categories. \n",
    "        assert partition in ['train', 'test'], \"Partition should be either 'train' or 'test'\"\n",
    "        self.path, self.num_points, self.partition=path, num_points, partition\n",
    "        self.transforms = transforms if isinstance(transforms, (tuple, list)) else [transforms]\n",
    "        self.data, self.label = load_data(partition, path)\n",
    "        \n",
    "        if type(category) == str:\n",
    "            assert category in m40_odered_labels, \"Please select a valid category label\"\n",
    "            category = m40_cat2int[category]\n",
    "        else:\n",
    "            assert category in [-1] + list(range(40)), \"Category index should be either -1 or a number in [0, 39]\"\n",
    "        \n",
    "        if category != -1:\n",
    "            mask = np.zeros_like(self.label).astype('bool')\n",
    "            mask[self.label == category] = 1\n",
    "            self.data = self.data[mask.squeeze(), ...]\n",
    "            self.label = self.label[mask]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        pointcloud = self.data[item][:self.num_points]\n",
    "        label = self.label[item]\n",
    "        for t in self.transforms:\n",
    "            pointcloud = t(pointcloud)\n",
    "        return pointcloud, label               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L70){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelNet40\n",
       "\n",
       ">      ModelNet40 (path:str, num_points:int, partition:str='train',\n",
       ">                  transforms=[], category=-1)\n",
       "\n",
       "A ModelNet40 class is necessary for loading and accessing the data, and it inherits from the torch.utils.Dataset class.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | path of the dataset |\n",
       "| num_points | int |  | number of points |\n",
       "| partition | str | train | which partition to use (`train` or `test`) |\n",
       "| transforms | list | [] | the transforms to apply on each sample |\n",
       "| category | int | -1 | select a specific category of the dataset either by index or by name. By default returns samples from all 40 categories. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/JohnRomanelis/pclab/blob/main/pclab/datasets/modelnet.py#L70){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelNet40\n",
       "\n",
       ">      ModelNet40 (path:str, num_points:int, partition:str='train',\n",
       ">                  transforms=[], category=-1)\n",
       "\n",
       "A ModelNet40 class is necessary for loading and accessing the data, and it inherits from the torch.utils.Dataset class.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | path of the dataset |\n",
       "| num_points | int |  | number of points |\n",
       "| partition | str | train | which partition to use (`train` or `test`) |\n",
       "| transforms | list | [] | the transforms to apply on each sample |\n",
       "| category | int | -1 | select a specific category of the dataset either by index or by name. By default returns samples from all 40 categories. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelNet40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "path = \"/home/vvr/Desktop/vlassisgiannis/new_exps/data\" #\"/home/ioannis/Desktop/programming/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dataset = ModelNet40(path, 1024, 'train')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the airplane category using the category label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dataset = ModelNet40(path, 1024, 'train', category = 'airplane')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the airplane category using the category index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dataset = ModelNet40(path, 1024, 'train', category = 0)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset with custom transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "transforms = [RandomPointDropout(), RandomShuffle(), UnitSphereNormalization(), AnisotropicScale(), ToTensor()]\n",
    "dataset = ModelNet40(path, 1024, 'train', transforms=transforms)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "\n",
    "def get_modelnet(path,\n",
    "                 version='standard',  # which version to return \n",
    "                 return_dls=True,     # return dataloaders instead of dataset\n",
    "                 batch_size=32):      # the batch_size to use if returning a dataloader\n",
    "    \"Get a version of ModelNet from a predefined set of versions, for faster coding\"\n",
    "    \n",
    "    if version == 'standard':\n",
    "    \n",
    "        # TODO: Try on train to load the dataset with 2048 points and use RandomPointKeep transform with 1024 points -> Better Augmentation\n",
    "        train_transforms = [RandomPointDropout(), RandomShuffle(), UnitSphereNormalization(), AnisotropicScale(), ToTensor()]\n",
    "        valid_transforms = [UnitSphereNormalization(), ToTensor()]\n",
    "    \n",
    "        train_dataset = ModelNet40(path, 1024, 'train', transforms = train_transforms)\n",
    "        valid_dataset = ModelNet40(path, 1024, 'test' , transforms = valid_transforms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if return_dls:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,   shuffle=True, num_workers=8, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=2*batch_size, shuffle=False,num_workers=8, drop_last=False) \n",
    "        \n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "    #else:\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get a predifined version of ModelNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_modelnet(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
