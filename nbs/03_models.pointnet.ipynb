{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fce956-59a1-42af-a20f-107eef6941db",
   "metadata": {},
   "source": [
    "# PointNet\n",
    "\n",
    "> Creating [PointNet](https://arxiv.org/abs/1612.00593). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276f7db-dfb8-4737-86e0-ee8f9e33b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models/pointnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f1da1-01cb-49b3-914b-3e0e075696e8",
   "metadata": {},
   "source": [
    "### NOTE: THIS PAGE NEEDS FORMATING AND ADDING GENERAL FUNCTIONALITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0d116-b97a-4d18-900d-a8001b4b53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bd8e9-cc58-413a-af20-55dd96a38246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    \"A linear layer that can be either used as a shared-mlp or as a block in a fully connected network\"\n",
    "    def __init__(self, in_channels, out_channels, fc=False, use_norm=True, use_relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # we can skip the bias if we use batch normalization\n",
    "        bias = not use_norm\n",
    "\n",
    "        layers = [nn.Linear(in_channels, out_channels, bias=bias) if fc else nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=bias)]\n",
    "\n",
    "        if use_norm:\n",
    "            layers.append(nn.BatchNorm1d(out_channels))\n",
    "\n",
    "        if use_relu:\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        # initializing the weights of the module\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init.kaiming_uniform_(self.net[0].weight, a=math.sqrt(2))\n",
    "        # bias initialization?\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad381523-96ca-461f-aa22-1bfd85e76da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "#| hide\n",
    "\n",
    "class MaxPool1D(nn.Module):\n",
    "    \"MaxPool1D\"\n",
    "    def forward(self, x):\n",
    "        return x.max(dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2dab8-1c84-41d0-ba82-51e674f783e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "#| hide\n",
    "\n",
    "# regularization loss used in PointNet\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0bfc2-8a4d-4772-8d78-a7416f3b5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class TNET(nn.Module):\n",
    "    \"The TNET network that is part of the PointNet architecture\"\n",
    "    def __init__(self, in_features:int): \n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.tnet = nn.Sequential(\n",
    "            # Initial feature aggregation\n",
    "            LinearLayer(in_features, 64),\n",
    "            LinearLayer(64, 128), \n",
    "            LinearLayer(128, 1024),\n",
    "            # max pooling\n",
    "            MaxPool1D(),\n",
    "            # MLP to create the final matrix\n",
    "            LinearLayer(1024, 512, fc=True),\n",
    "            LinearLayer(512, 256, fc=True),\n",
    "            LinearLayer(256, in_features * in_features, fc=True, use_norm=False, use_relu=False)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            # we want the initial state of the network to be as close a possible to the identity matrix\n",
    "            # so we need to set a high value at the bias of the element in the main diagonal and small values\n",
    "            # to the rest of the biases and the weights of the output layer\n",
    "            diag_indx = torch.arange(0, self.in_features * self.in_features-1, self.in_features+1)\n",
    "            \n",
    "            # setting the bias to be a small number\n",
    "            self.tnet[-1].net[0].bias.fill_(0.00001)\n",
    "            # setting the bias of the elements in the diagonal to be equal to 1.0\n",
    "            self.tnet[-1].net[0].bias[diag_indx] = 1.0\n",
    "            # aggigning a small value to the weights of the last layer\n",
    "            self.tnet[-1].net[0].weight *= 0.0001 \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tnet(x)\n",
    "        # reshape x to create a matrix\n",
    "        x = x.reshape(-1, self.in_features, self.in_features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f44b88-10c5-403f-af3d-0cbb406fb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class PointNetCore(nn.Module):\n",
    "    'As PointNet core we consider the remains of the classification network if we remove the classification head. '\n",
    "    def __init__(self, point_features:int): # values per point, usually the x,y,z coordinates \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_TNET = TNET(3)\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            LinearLayer(3, 64),\n",
    "            LinearLayer(64, 64)\n",
    "        )\n",
    "        self.feature_TNET = TNET(64)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            LinearLayer(64, 64), \n",
    "            LinearLayer(64, 128),\n",
    "            LinearLayer(128, 1024)\n",
    "        )\n",
    "\n",
    "        # creating variables to store the m1, m2 matrices produced by the TNET\n",
    "        self.m1 = None\n",
    "        self.m2 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # calculating the first orthogonal matrix\n",
    "        # to transform input features\n",
    "        m1 = self.input_TNET(x)\n",
    "        x = m1 @ x # Multiply x with the transform matrix\n",
    "        # passing through the first series of mlps\n",
    "        x = self.mlp1(x)\n",
    "        # Applying second feature transform\n",
    "        m2 = self.feature_TNET(x)\n",
    "        x = m2 @ x\n",
    "        # passing through the second series of mlps\n",
    "        x = self.mlp2(x)\n",
    "\n",
    "        # storing the m1 and m2 matrices\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_TNET_matrices(self):\n",
    "        return self.m1, self.m2\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        return feature_transform_regularizer(self.m1) + feature_transform_regularizer(self.m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b37fa3-7c18-4fc8-8252-2a97f1992973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class PointNetCLSHead(nn.Sequential):\n",
    "    'The classification head used in PointNet'\n",
    "    def __init__(self, in_channels:int,  # feature dimension of the latent space vector \n",
    "                       num_classes:int): # number of classes\n",
    "        super().__init__(\n",
    "            LinearLayer(in_channels, 512, fc=True),\n",
    "            LinearLayer(512, 256, fc=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            LinearLayer(256, num_classes, fc=True, use_norm=False, use_relu=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa113e-0fbb-4f78-9b8e-64ead1d72bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class PointNetCLS(nn.Module):\n",
    "    'PointNet variant for classification'\n",
    "    def __init__(self, \n",
    "                 point_features:int, # values per point, usually the x,y,z coordinates \n",
    "                 num_classes:int):   # number of classes \n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extraction for each point\n",
    "        self.core = PointNetCore(point_features)\n",
    "        # Feature aggregation - Symmetric Function\n",
    "        self.maxpool = MaxPool1D()\n",
    "        # Classification head  \n",
    "        self.cls_head = PointNetCLSHead(1024, num_classes)\n",
    "    \n",
    "    def regularization_loss(self):\n",
    "        return self.core.regularization_loss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.core(x)\n",
    "        \n",
    "        args = None\n",
    "        if isinstance(x, tuple):\n",
    "            args = x[1:]\n",
    "            x = x[0]\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        x = self.cls_head(x)\n",
    "\n",
    "        if args is not None:\n",
    "            return x, *args\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1edb71-c356-4878-b678-48c30ae6c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class PointNetSeg(nn.Module):\n",
    "    \"A variant of PointNet that outputs a feature vector for each point in the point cloud\"\n",
    "    def __init__(self, in_channels:int=3): # values per point, usually the x,y,z coordinates \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_TNET = TNET(in_channels)\n",
    "        self.mlp1 = LinearLayer(in_channels, 64)\n",
    "        self.mlp2 = LinearLayer(64, 128)\n",
    "        self.mlp3 = LinearLayer(128, 128)\n",
    "\n",
    "        self.feature_TNET = TNET(128)\n",
    "        self.mlp4 = LinearLayer(128, 512)\n",
    "        self.mlp5 = LinearLayer(512, 2048)\n",
    "\n",
    "        self.maxpool = MaxPool1D()\n",
    "\n",
    "        self.mlp6 = nn.Sequential(\n",
    "            LinearLayer(3008, 256),\n",
    "            LinearLayer(256, 256),\n",
    "            LinearLayer(256, 128),\n",
    "            LinearLayer(128, 3)\n",
    "        )\n",
    "\n",
    "        # creating variables to store the m1, m2 matrices produced by the TNET\n",
    "        self.m1 = None\n",
    "        self.m2 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        _, _, N = x.shape\n",
    "        features = []\n",
    "        \n",
    "        m1 = self.input_TNET(x)\n",
    "        x = m1 @ x # Multiply x with the transform matrix\n",
    "\n",
    "        # passing through the first series of mlps\n",
    "        x = self.mlp1(x)\n",
    "        features.append(x)\n",
    "        x = self.mlp2(x)\n",
    "        features.append(x)\n",
    "        x = self.mlp3(x)\n",
    "        features.append(x)\n",
    "        # Applying second feature transform\n",
    "        m2 = self.feature_TNET(x)\n",
    "        x = m2 @ x\n",
    "        features.append(x)\n",
    "        # passing through the second series of mlps\n",
    "        x = self.mlp4(x)\n",
    "        features.append(x)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.maxpool(x)\n",
    "        features.append(x.unsqueeze(-1).repeat(1,1,N))\n",
    "\n",
    "        # concatenating the features\n",
    "        feat = torch.cat(features, dim=1)\n",
    "\n",
    "        out_points = self.mlp6(feat)\n",
    "\n",
    "        # storing the m1 and m2 matrices\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "\n",
    "        return out_points.permute(0,2,1)\n",
    "\n",
    "    def get_TNET_matrices(self):\n",
    "        return self.m1, self.m2\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        return feature_transform_regularizer(self.m1) + feature_transform_regularizer(self.m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34622b73-82bd-4876-b817-8c4e10d31249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2048, 3])\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "model = PointNetSeg().cuda()\n",
    "x = torch.rand(6, 3, 2048).cuda()\n",
    "out = model(x)\n",
    "\n",
    "print(out.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b04c1a-302d-4e13-8a10-796dc228008c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
